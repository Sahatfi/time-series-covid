{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1380ec3-68d6-4251-b33f-cfafe5e201f2",
   "metadata": {},
   "source": [
    "# 1 Introduction and clinical context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff6cdd6-ece6-4280-92a2-b8e7018e743b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff401c54-802c-442b-8745-76c72693c694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6942713f-3c2e-4538-aa18-8354977174c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "837603f9-98c3-43cc-a00a-10768720e757",
   "metadata": {},
   "source": [
    "# 2 Defintions methods and hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab27541-893b-43c3-bcf3-db97016290c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2813cd73-9773-48ee-bf5b-c6f432724636",
   "metadata": {},
   "source": [
    "# 3 Import of data and libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a6f835-69c6-4839-888a-cac11becc2ee",
   "metadata": {},
   "source": [
    "## 3.1 Import of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc793ca8-df34-4fa3-9f93-eb5e84594b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing basic data analyst libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Importing libraries for SQL querrying\n",
    "import duckdb "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d3603c-6982-4308-82b7-f144456b5a09",
   "metadata": {},
   "source": [
    "##3.2 Importing tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d98b1a6-2877-4596-8313-9e1867f18c41",
   "metadata": {},
   "source": [
    "I decided to import all the tables relevant for my analysis at this point. I will treat them as a database and later on i will look at them in detail. Now I will just import them one by one whereas querrying and cleaning comes a bit later in separate stages. I chose this approach because i find it more logically organised compared to other solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd34dc1-8988-482c-80ff-78f6dc9c6914",
   "metadata": {},
   "source": [
    "###3.2.1 Importing confirmed cases table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661943cf-0e35-4eed-a45c-1802dd7ad2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases = pd.read_csv('data/raw/confirmed_global.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389d255f-b2b1-47f5-a01d-dc9f4d52a686",
   "metadata": {},
   "source": [
    "Verifying import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7979b4f-3849-4ae5-8b43-54d506e81b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cases.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba95d563-b0fe-4301-9f97-e7ef7ce91214",
   "metadata": {},
   "source": [
    "##### ---Cases dataset imported successfully---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7406c85-43d8-474d-b076-1f6a0d66bf54",
   "metadata": {},
   "source": [
    "### 3.2.2 Importing death cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e9a1e5-fbde-4846-86c4-74ad856c91f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deaths = pd.read_csv('data/raw/deaths_global.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee17518-fdf9-415f-a225-30aa54526cdc",
   "metadata": {},
   "source": [
    "Verifying import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ebbd4-552f-4eae-bf0a-3723c94e98c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(df_deaths.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cff8e2-9fd7-4a8b-8031-061c217c12cf",
   "metadata": {},
   "source": [
    "##### ----Deaths dataset importet successfully----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d486258-b68b-4077-b375-c708b51cdeef",
   "metadata": {},
   "source": [
    "### 3.2.3 Importing recovered cases dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7429274-3c2c-4410-aba5-01614f548271",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovered = pd.read_csv('data/raw/recovered_global.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d36ef-0074-4bf4-b53f-e40199f9ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_recovered.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a75a5-b315-47f5-b3d6-883e27c35c2d",
   "metadata": {},
   "source": [
    "##### ----Recovered dataset importet successfully!----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e578c79-44d4-4e1d-a70d-b81e4e0f90c7",
   "metadata": {},
   "source": [
    "# 4 Inspecting cleaning and preparing datasets for melting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709aab47-3590-4e05-98ec-f4ed0969c869",
   "metadata": {},
   "source": [
    "In this sections I will get acquianted with dataset, melt it, deal with missings and prepare it for melting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9734eb-32f6-4d84-a8ca-b753ebb5e81b",
   "metadata": {},
   "source": [
    "## 4.1 Inspecting cleaning and preparing the dataset with cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f54a9-9221-4a9b-82a5-519f3917cc72",
   "metadata": {},
   "source": [
    "### 4.1.1 Inspecting the dataset with cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182554c-3b5d-48f9-827a-0bd3264a4e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cases.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b2d98c-5c61-462b-a0c4-2f212d9ae31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cases.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275cbe7b-52aa-44ce-9bb8-1f1e1be53508",
   "metadata": {},
   "source": [
    "Shape of the dataset is 274 rows and 449 columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d4aa3-da1f-42d7-8be5-dc54897184d0",
   "metadata": {},
   "source": [
    "From the first glance I see identifier columns such as province/state, Country/Relogion, Latitude and longitude. There are 449 columns where majority corresponds to individual dates within given period of time. To confirm that only date columns follow 'Long', and that there are no unexpected columns in between, I will iterate through the column names and count the columns to crosscheck whether i itterate through columns correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81382358-5877-4456-aef9-181a342ba34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for col in df_cases:\n",
    "    print(col)\n",
    "    count = count + 1\n",
    "    \n",
    "print(\"the column count is: \", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3fc440-9597-420c-b431-05b0bd542932",
   "metadata": {},
   "source": [
    "All the respective columns  after 'Long' seem to represent individual dates and column count from the loop is in agreement with the column count from df_cases.head(). Next I need to check data types of individual columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab53c401-eb67-4b49-b574-605532f13000",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_integer = 0\n",
    "count_other_datatypes = 0\n",
    "for col in df_cases:\n",
    "    print(df_cases[col].dtype)\n",
    "    if df_cases[col].dtype == int:\n",
    "        count_integer = count_integer +1\n",
    "    else:\n",
    "        count_other_datatypes = count_other_datatypes + 1\n",
    "\n",
    "print('Integer count is:', count_integer, '\\n Other data types count is:', count_other_datatypes)\n",
    "if count_integer == 445:\n",
    "    print('All date-columns are integers!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a4c21b-f856-4945-aacb-2991efef5148",
   "metadata": {},
   "source": [
    "Loop confirmed that all date columns are formated as an integer datatype. I see that other datatypes in the dataset are objects and float. I will confirm it with command .info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac9d221-0a57-4ca4-ab30-a45762262f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16472b40-830f-46e9-8947-9750ff32ca4c",
   "metadata": {},
   "source": [
    "Verification showed exactly those datatypes i noticed  above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcdc72e-35bb-4f54-8419-97ce6fe2b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cases.describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e5b01c-f0a5-4cd6-a6ed-87f047fe428d",
   "metadata": {},
   "source": [
    "Describe command gives me an overview over the dataset. There are a lot of missing values in province/state. I have to investigate this variable closer. Country/region column will likely be the variable of interest and will serve us as identifier, Whereas latitute and longitude are not interesting forour analysis. Even though some viruses are known to spread better in colder or warmer climates, Cross-country comparisons in cases between the countries are not feasible because we donÂ´t have data on people tested and countries were very different in test measures and  test equipment. In this dataset we lack the data for it. I will not check dataset with .describe(). Quick overview shows that there were 0 cases in a begining whereas number of cases began to increase and fluctuate over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b5aba2-4264-4aaa-a36c-31ace31f99e3",
   "metadata": {},
   "source": [
    "### 4.1.2 Cleaning the dataset with cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8056fb-3ede-41c7-b50c-3244089b1b18",
   "metadata": {},
   "source": [
    "I am checking if there are any missing values in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83fdd91-f8ca-40e7-91c3-f99ef7eb70d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_cases.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6721e66d-92a9-41e2-860d-5bc2d7065653",
   "metadata": {},
   "source": [
    "I cannot see the whole dataset, but the output indicates that Province/state has missing values. I am going to investigate it further along with other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5686179-6111-47bb-b765-4f29b6944d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcf170c-f367-41c4-9762-3d2cb4c5c6aa",
   "metadata": {},
   "source": [
    "It seems that longitude latitude and province contain misssing values whereas dates seem to contain no missing value. I need to check my assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b9bf89-fed4-431e-b389-73af1e266a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases.isna().any().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ec2d1-e70e-4ca3-a4ce-e87b87598d98",
   "metadata": {},
   "source": [
    "There are three columns in the df_cases. They are Province/State, Lat, Long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a2a96-413b-4f09-833d-31ceab009846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb40f18a-4920-4760-a138-3b65e5fbeafb",
   "metadata": {},
   "source": [
    "There are three columns in the df_cases. They are Province/State, Lat, Long.\n",
    "Before I go further with cleaning and droping, want to check which column is the most pertinent one to become identifier column during melting. The two most valiable options are Province/state and Country/Region. I will extend the jupyter notebook output to contain up to 500 rows and columns which should be sufficient size to cover the entire df_cases dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d720c-c5c0-41a7-92e5-a0cf5420bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extending output for rows\n",
    "pd.set_option('display.max_rows', 300)\n",
    "#extending output for columns\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa707e22-97f6-4821-8cd9-4d82ae058e30",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(df_cases[['Province/State', 'Country/Region']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9297f0f-3c30-496c-a8ba-731855f6745c",
   "metadata": {},
   "source": [
    "I confirm that column 'Province/State' is of no interest as it shows either overseas territories and provinces/states within a few countries.Contrary, Norway and Slovakia are both within Country/Region column which will become our identifier. Now I will strip the dataset from all the unneccesarry columns and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a71ed0-e4ea-469e-b3f0-17a3f478896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_filtered = \"\"\"\n",
    "SELECT *\n",
    "FROM df_cases\n",
    "WHERE \"Country/Region\" = 'Norway' OR \"Country/Region\" = 'Slovakia';\n",
    "\"\"\"\n",
    "df_cases = duckdb.query(df_cases_filtered).to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b91bbed-0f7f-48b2-8f48-ed09b649830f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Checking whether i filtered rows correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c87a4-0424-476d-863f-36769166ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cases.iloc[:, 1:])\n",
    "print(type(df_cases), df_cases.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c70464-1fb2-4beb-88e1-1fedb8007324",
   "metadata": {},
   "source": [
    "I correctly filtered just relevant rows and transformed querried data into dataframe. There are two rows- Slovakia and Norway with number of columns(449) remained unchanged. Now I will proceed with dropping all the unneccessarry columns. namely: \n",
    "'Province/State', \n",
    "'Long', \n",
    "'Lat'\n",
    "\n",
    "As mentioned earlier, variables lattitude and longitude are of  no value in our analysis, whereas province/state is variable indicating a region within larger countries.Countries of interest are slovakia and Norway and we have no addotional data on specific locations within those countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40558ed-5126-42fd-8d1c-31c9013f7cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases.drop(['Province/State', 'Long','Lat',], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0270844-3fbd-459b-892c-3ef612393007",
   "metadata": {},
   "source": [
    "Checking if there are some missing values in the dataset:\n",
    "df_cases_filtered.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a50a7e-56fe-4199-9e1f-31e28f0095e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df_cases,df_cases.shape)\n",
    "print('', df_cases.isna().any().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834ded40-89e3-4186-8f2b-41302710ac11",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "I correctly dropped all the unneccessarry rows and dataset is ready to melt. But before I will do it I will prepare datasets with deaths and recovered cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ab597-2659-4fbb-ae4d-e7815a21a4d5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## 4.2 Inspecting cleaning and preparing the dataset with deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f65c8d-5045-4faa-b1c9-d1d6c28c0d6e",
   "metadata": {},
   "source": [
    "### 4.2.1 Inspecting the dataset with deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cc65d2-f510-49f0-ad2f-fdb5b56538cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_deaths.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc26e09-f9bd-4ac9-95d0-6a92340aa920",
   "metadata": {},
   "source": [
    "The deaths dataset has the same number of rows(274) and columns (449) as the cases dataset. its a good indication because the process of cleaning checking and extracting of data will be very simmilar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f619f3-a67e-4ed7-be33-9563ec7e2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_deaths.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b80890-6985-4736-bf4a-5104ff9e787a",
   "metadata": {},
   "source": [
    "Again, earlier dates indicate zero dates whereas number of deaths towards the later period is higher and steadily increasing Whereas first five variables: 'Province/State' 'Country/Region 'Lat''Long' seem to be identical through all the datasets. I have to confirm this assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a950dd1-0450-4017-8aa2-dfa6ac45e0ec",
   "metadata": {},
   "source": [
    "I am checking what datatypes exist in the dataset deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bff74f1-632d-4944-a839-639948be60f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deaths.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c47b04b-836b-4259-ae98-3062be5e81f8",
   "metadata": {},
   "source": [
    "df_deaths dataset seem to have identical types  two float columns (lat, long), two object columns (Province/State Country/Region) and 445 integer(date columns). I will verify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa9e4b-3cd7-4798-983c-a57b1ddb0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_deaths['Country/Region'].dtype)\n",
    "print(df_deaths['Country/Region'].dtype)\n",
    "print(df_deaths['Long'].dtype)\n",
    "print(df_deaths['Lat'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26efbc-8ab9-4cd3-bfb8-a37072901422",
   "metadata": {},
   "source": [
    "I confirm my assumption about float and object columns, I will check the date(integer columns as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf00249-3ea6-43d2-bd3b-9848d3d11140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering dataset so there are only dates\n",
    "df_deaths_only_date = df_deaths.iloc[:, 4:]\n",
    "#Creating loop to check which type the column is\n",
    "date_counter = 0\n",
    "for col in df_deaths_only_date:\n",
    "    print(df_deaths_only_date[col].dtype)\n",
    "    date_counter +=1 \n",
    "\n",
    "print(date_counter)\n",
    "print(df_deaths_only_date.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19438b9-05fb-4102-afad-646bfffdb84f",
   "metadata": {},
   "source": [
    "I confirm that the dataset contains 445 integers! I am finished with scrutinizing the dataset with deaths and I move further to clean it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521ef72-685f-4390-af56-08e5e2407305",
   "metadata": {},
   "source": [
    "### 4.2.2 Cleaning the dataset with deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d514350-45d0-43a6-903a-b43ffa58c2c5",
   "metadata": {},
   "source": [
    "I first check whether columns contain missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab6d369-fa61-4afa-8557-38162be741d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_deaths.isna().any())\n",
    "df_deaths.isna().any().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171c175-d511-4661-94eb-1a382c37ff82",
   "metadata": {},
   "source": [
    "#I will check how many columns with missing values are present. if there are three we know they are those:\n",
    " Province/State      \n",
    " Lat       \n",
    " Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef2716-f5c8-43ee-974c-738b82d93ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deaths.isna().any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f261c641-4976-4326-abda-92e1a7161f15",
   "metadata": {},
   "source": [
    "I confirm the assumption about the missing values. Now I check identifier columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90dc99c-9adf-49a1-b48e-dbbf6e6e07ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9116861f-4988-449b-9edc-04b9acbc2910",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_deaths['Province/State'],df_deaths['Country/Region'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4956901-9207-47d8-8517-385d7c261344",
   "metadata": {},
   "source": [
    "I will drop the Long, Lat and Province/State columns as they are of no interest for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc533768-597b-458a-886d-4619a3f2982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deaths.drop(['Province/State', 'Long', 'Lat'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d2d708-097e-4ed5-9ca9-08a42f8a0a6e",
   "metadata": {},
   "source": [
    "Filtering rows with Slovakia and Norway and re-writing original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d276e53-c554-44ba-8eb3-47491acdd964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deaths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deb9e7e-54e1-4332-a449-2aa572730c5b",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4cb18-e926-4a74-b03b-329f48a39b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#row-filtering\n",
    "df_deaths_filtered = \"\"\"\n",
    "SELECT * FROM df_deaths\n",
    "WHERE \"Country/Region\" = 'Slovakia' OR \"Country/Region\" = 'Norway' \"\"\"\n",
    "#re-writing df_deaths\n",
    "df_deaths = duckdb.query(df_deaths_filtered).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc6966-a51e-4775-9e03-13049508a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(' The dataset has', df_deaths.isna().any().sum(), 'missings', df_deaths.shape, df_deaths.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896cc2f5-188d-4b8a-a9ef-923b6c5627ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00a9f19-9ee8-4b24-b35b-7f5e049277a9",
   "metadata": {},
   "source": [
    "Dataset is correctly cleaned and filtered with dates as integers, identifier column som object and zero missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95b648b-9443-4874-ba3f-ee59a4ffff45",
   "metadata": {},
   "source": [
    "## 4.3 Inspecting cleaning and preparing the dataset with recovered cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0298750b-1733-484d-8654-2b18a3ee9b71",
   "metadata": {},
   "source": [
    "### 4.3.1 Inspecting the dataset with recovered cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73c0b9b-802f-464a-a407-970573911932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05692f8-6997-4665-a8e8-f93082ebe704",
   "metadata": {},
   "source": [
    "The dataset seems to follow the exactly same pattern as the two  datasets above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0346bfcf-270e-4748-abf1-8198cdbfc907",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e62605-7860-4831-b50d-ab1fbe2c95ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovered.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286325a8-69d5-4139-8a5c-008e17288817",
   "metadata": {},
   "source": [
    "Contrary to other columns variable lat is coded as an object. It doesnÂ´t have an effect on my decision to drop it, it is just peculiar observation. Now I check whether there is  Norway and Slovakia in country/region variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6d12cd-5b37-4df7-acab-7337390a21de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking country column\n",
    "print(df_recovered['Country/Region'].isin(['Norway']).any())\n",
    "print(df_recovered['Country/Region'].isin(['Slovakia']).any())\n",
    "\n",
    "\n",
    "#Checking state column\n",
    "\n",
    "print(df_recovered[\"Province/State\"].isin([\"Slovakia\"]).any())\n",
    "print(df_recovered['Province/State'].isin(['Norway']).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09936e-12d0-447e-b3b1-4c5939aa9b66",
   "metadata": {},
   "source": [
    "We did find both countries in Country/Region, Whereas we didnt find any of the countries of interest in Province/State. This means again that identifier will be Country/Region. I will confirm that dates are integers in subsequent code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27bd60c-efda-4227-bc73-9c09cffa9097",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_dates = df_recovered.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7acee0-b8ab-4108-a017-56c1039b25be",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_dates.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56a582-aa37-4a70-8ad6-c795cfe895be",
   "metadata": {},
   "source": [
    "All dates are integers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd057326-d23c-4dff-8647-10dfc6acb85c",
   "metadata": {},
   "source": [
    "### 4.3.2 Cleaning the dataset with recovered cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed53d4-5f6c-46b8-874f-aa505fcd73dd",
   "metadata": {},
   "source": [
    "I will filter the rows dataset applying boolean mask to relevant rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a054de-1270-454a-9f46-dce47d3c0dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recoveredd =df_recovered[(df_recovered['Country/Region'] == 'Slovakia') | (df_recovered['Country/Region'] == 'Norway')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b8218e-61d6-418f-b04f-34d15eea989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reassigning the new table to the old one\n",
    "df_recovered = df_recoveredd\n",
    "df_recovered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d9dfc6-43d0-47f6-8fd9-5361196673f5",
   "metadata": {},
   "source": [
    "I need to change row indexes. I reset them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd6bf6-363f-4441-892a-2b744f6d4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovered.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ab0ab6-28d1-46bd-b7f0-12ac855bdfc6",
   "metadata": {},
   "source": [
    "Now I  drop all the irelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aad038e-6743-4038-8996-bc82e79a04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping unneccessarry columns\n",
    "df_recovered.drop(['Long', 'Lat', 'Province/State'], axis = 1, inplace = True)\n",
    "df_recovered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7bb0dd-bc4a-4296-8166-7b69aa87719d",
   "metadata": {},
   "source": [
    "Cleaning successfull!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1e2a62-d4ff-4dcd-9f6a-9a6b1e0eefc6",
   "metadata": {},
   "source": [
    "## 4.4 Checking the tables all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265700e8-77b3-41ee-b527-8198e4f2a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f28e2cf-3f15-4e6e-bc04-cf40219c037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdcc46-1869-4db5-bff4-9720a6f6ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf635b8-3a63-4f97-ad98-a1e99afa8835",
   "metadata": {},
   "source": [
    "All the tables seem to be correctly filtered, I confirm that by printing out datatypes in columns of respective dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953b9bb-48ff-40ae-937e-c60f461b6f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_recovered.info())\n",
    "print(df_deaths.info())\n",
    "print(df_cases.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af13d529-47bc-462c-9b64-b097b6611fee",
   "metadata": {},
   "source": [
    "All the dataframes have 445 integers(dates) and 1 object(identifier). I will finally confirm a cleanliness of dataset viewing their shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35ebff-489f-4f2e-95cc-27da6a9dcc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_recovered.shape)\n",
    "print(df_deaths.shape)\n",
    "print(df_cases.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58620eba-2869-4c83-b3b2-98428b1228b4",
   "metadata": {},
   "source": [
    "All of them have two rows(Slovakia and Norway) and 446 columns out of which 445 are date columns and 1 is identifier. I confirm dataset is ready for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f61b64-173d-4789-8b69-bd8aea1a3c6a",
   "metadata": {},
   "source": [
    "# 5 Melting the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c005368-6be3-4e6e-ac92-a02962c04f93",
   "metadata": {},
   "source": [
    "## 5.1 Melting the cases dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d720e1-2839-489c-9c5e-c7d6b9c3fb03",
   "metadata": {},
   "source": [
    "Melting means that I change format of the table. Instead of having 446 columns, I want to have just three. these are:\n",
    "country/region, date and number of cases.The table will be long because each date column will be listed as row twice- one for slovakia and same date for norway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd096ef0-b837-4b84-a823-8aa4e524ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases = df_cases.melt(id_vars = 'Country/Region', var_name = 'date', value_name = \"cases_number\").copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659b9cda-e599-4295-80f8-79c14b6d0c2d",
   "metadata": {},
   "source": [
    "Checking the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c566b-82c7-41dc-b77a-30d707058d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc78bd5-0a52-4d62-8084-3e2c6ad5a0c5",
   "metadata": {},
   "source": [
    "The table is melted correctly, there are 890 rows which is 455 per country this number of rows corresponds to number of date columns in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e06f9-addc-4d0d-bab3-6aa327a3b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5.2 Melting the deaths dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a361b-c764-4e6f-9ec6-2ec8446f8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deaths = df_deaths.melt(id_vars = \"Country/Region\", var_name = 'date', value_name = 'deaths_number').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72abc0e-3ca0-4d4d-a1e8-d97840e0fa13",
   "metadata": {},
   "source": [
    "Checking the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce99187-b8cf-4725-a2b8-2eeda5dc952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1319b11-7e3f-4e27-84b6-5d1cd4c1e47e",
   "metadata": {},
   "source": [
    "I confirm that columns are named correctly and shape of the table 890 x 3 is desirable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5c85e-8a5a-4671-90cb-bdcd8c279e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5.3 Melting the dataset with recovered cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9b4c44-aa91-43bc-8a36-24f86fae8655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovered = df_recovered.melt(id_vars = \"Country/Region\", var_name = \"date\", value_name = 'recovered_number').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1995bcd1-2e5a-457d-b559-d33af2cde099",
   "metadata": {},
   "source": [
    "Checking the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86ab78-ed07-4a3a-a8a4-79533ce19834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f431281c-bf87-442b-94f9-90b19186c0c8",
   "metadata": {},
   "source": [
    "I confirm that table shape matches perfectly the table shapes of recovered and cases tables. All three tables begin and finish with the same date. Lastly i check if there are any duplicates in the date columns. Each dataset should not have more than 2 duplicates of date(corresponding to 2 respective countries) in itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa97f5-ee53-412a-a0fe-c2162c554df6",
   "metadata": {},
   "source": [
    "Accessing the number of duplicates for each date in each dataset(correct should be 2 for each date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98414b8c-1cec-45f8-a77e-5b148eb13039",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_duplicates_size = df_cases.groupby(\"date\").size()\n",
    "deaths_duplicates_size = df_deaths.groupby(\"date\").size()\n",
    "recovered_duplicates_size = df_recovered.groupby(\"date\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db6414-8be3-4315-b73f-2aa3873ed3e8",
   "metadata": {},
   "source": [
    "Checking if each date contains no more or no less than two duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a842aee2-2bba-4ffa-bdeb-8a10e32d8e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print((cases_duplicates_size == 2).all())\n",
    "print((deaths_duplicates_size == 2).all())\n",
    "print((recovered_duplicates_size == 2).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c6f32-3aee-4e8b-aff0-6813e49e478f",
   "metadata": {},
   "source": [
    "Melting successfull!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66525832-b53f-46da-92a4-9efc7e8e523c",
   "metadata": {},
   "source": [
    "6. Merging the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c2e8d-c434-43e7-87a0-8c02d6abc2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merging datasets using SQL querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b085205a-4bcf-4e9b-81db-b773667c1c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeseries = \"\"\"SELECT c.\"Country/Region\" AS country,\n",
    "                          c.\"cases_number\", \n",
    "                          d.\"deaths_number\", \n",
    "                          r.\"recovered_number\"\n",
    "FROM df_cases\n",
    "LEFT JOIN (SELECT Country/Region,\n",
    "                  date\t\n",
    "                  deaths_number FROM df_deaths) AS d\n",
    "LEFT JOIN df_recovered AS r\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427e7507-d3ed-4d5e-b516-ef99836be6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transforming query to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174df805-e04e-407a-829d-c99560313238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeseries = duckdb.query(timeseries).to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5a339d-dd80-4a11-a5bc-54e3c84466ea",
   "metadata": {},
   "source": [
    "Checking integrity of the merged dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ed067c-6d5e-48cb-a5d8-38e53aa75f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99662ebf-c67b-487a-9f2c-1a1925b58890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
